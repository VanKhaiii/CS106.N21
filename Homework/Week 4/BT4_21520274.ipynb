{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Import Necessary Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "d0A121VtcpHC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhSyhfEy4XSD"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython import display\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Support Function\n"
      ],
      "metadata": {
        "id": "Y-un1M_-ctv6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWLnvY7VBvIZ"
      },
      "source": [
        "def play(env, policy, render=False):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = policy[state]\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "        if render:\n",
        "            env.render()\n",
        "            time.sleep(0.2)\n",
        "            if not done:\n",
        "                display.clear_output(wait=True)\n",
        "        state = next_state\n",
        "\n",
        "    return (total_reward, steps)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8Q1qMxD6Po"
      },
      "source": [
        "def play_multiple_times(env, policy, max_episodes):\n",
        "    success = 0\n",
        "    list_of_steps = []\n",
        "    for i in range(max_episodes):\n",
        "        total_reward, steps = play(env, policy)\n",
        "\n",
        "        if total_reward > 0:\n",
        "            success += 1\n",
        "            list_of_steps.append(steps)\n",
        "\n",
        "    print(f'Number of successes: {success}/{max_episodes}')\n",
        "    print(f'Average number of steps: {np.mean(list_of_steps)}')\n",
        "    return success/max_episodes "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSomNpxJE5lP"
      },
      "source": [
        "def policy_evaluation(env, policy, max_iters=500, gamma=0.9):\n",
        "    # Initialize the values of all states to be 0\n",
        "    v_values = np.zeros(env.observation_space.n)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        prev_v_values = np.copy(v_values)\n",
        "\n",
        "        # Update the value of each state\n",
        "        for state in range(env.observation_space.n):\n",
        "            action = policy[state]\n",
        "\n",
        "            # Compute the q-value of the action\n",
        "            q_value = 0\n",
        "            for prob, next_state, reward, done in env.P[state][action]:\n",
        "                q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
        "\n",
        "            v_values[state] = q_value # update v-value\n",
        "        \n",
        "        # Check convergence\n",
        "        if np.all(np.isclose(v_values, prev_v_values)):\n",
        "            # print(f'Converged at {i}-th iteration.')\n",
        "            break\n",
        "    \n",
        "    return v_values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_extraction(env, v_values, gamma=0.9):\n",
        "    # initialize\n",
        "    policy = np.zeros(env.observation_space.n, dtype=np.int)\n",
        "\n",
        "    # loop through each state in the environment\n",
        "    for state in range(env.observation_space.n):\n",
        "        q_values = []\n",
        "        # loop through each action\n",
        "        for action in range(env.action_space.n):\n",
        "            q_value = 0\n",
        "            # loop each possible outcome\n",
        "            for prob, next_state, reward, done in env.P[state][action]:\n",
        "                q_value += prob * (reward + gamma * v_values[next_state])\n",
        "            \n",
        "            q_values.append(q_value)\n",
        "        \n",
        "        # select the best action\n",
        "        best_action = np.argmax(q_values)\n",
        "        policy[state] = best_action\n",
        "    \n",
        "    return policy"
      ],
      "metadata": {
        "id": "GbpiB6EZl-TH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runtime_data = []\n",
        "winrate_data = []"
      ],
      "metadata": {
        "id": "13fI_uYOLO7o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Value Iteration\n"
      ],
      "metadata": {
        "id": "dksRmaFXUpu6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh4akjMSHJBF"
      },
      "source": [
        "def value_iteration(env, max_iters=500, gamma=0.9):\n",
        "    # initialize\n",
        "    v_values = np.zeros(env.observation_space.n)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        prev_v_values = np.copy(v_values)\n",
        "\n",
        "        # update the v-value for each state\n",
        "        for state in range(env.observation_space.n):\n",
        "            q_values = []\n",
        "            \n",
        "            # compute the q-value for each action that we can perform at the state\n",
        "            for action in range(env.action_space.n):\n",
        "                q_value = 0\n",
        "                # loop through each possible outcome\n",
        "                for prob, next_state, reward, done in env.P[state][action]:\n",
        "                    q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
        "                \n",
        "                q_values.append(q_value)\n",
        "            \n",
        "            # select the max q-values\n",
        "            best_action = np.argmax(q_values)\n",
        "            v_values[state] = q_values[best_action]\n",
        "        \n",
        "        # check convergence\n",
        "        if np.all(np.isclose(v_values, prev_v_values)):\n",
        "            print(f'Converged at {i}-th iteration.')\n",
        "            break\n",
        "    \n",
        "    return v_values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runtimes = []\n",
        "winrates = []"
      ],
      "metadata": {
        "id": "zdAHMs6PLlIR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1. FrozenLake-v1"
      ],
      "metadata": {
        "id": "FiWjOOP5w8yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v1')\n",
        "\n",
        "start = time.time()\n",
        "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)\n",
        "end = time.time()\n",
        "print(\"Runtime: \", end-start)\n",
        "\n",
        "optimal_policy = policy_extraction(env, optimal_v_values, gamma=0.9)\n",
        "winrate = play_multiple_times(env, optimal_policy, 1000)\n",
        "\n",
        "runtimes.append(end-start)\n",
        "winrates.append(winrate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "albndOjdxUTL",
        "outputId": "4c16bd51-b188-47ec-e9ee-81551e548e2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 79-th iteration.\n",
            "Runtime:  0.04733848571777344\n",
            "Number of successes: 717/1000\n",
            "Average number of steps: 37.07670850767085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.2. FrozenLake8x8-v1"
      ],
      "metadata": {
        "id": "IAz1Np_mxG2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake8x8-v1')\n",
        "\n",
        "start = time.time()\n",
        "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)\n",
        "end = time.time()\n",
        "print(\"Runtime: \", end-start)\n",
        "\n",
        "optimal_policy = policy_extraction(env, optimal_v_values, gamma=0.9)\n",
        "winrate= play_multiple_times(env, optimal_policy, 1000)\n",
        "\n",
        "runtimes.append(end-start)\n",
        "winrates.append(winrate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EweTgzZPIagy",
        "outputId": "174ded01-ca72-4cc7-8070-c80785f1ba28"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 117-th iteration.\n",
            "Runtime:  0.21391034126281738\n",
            "Number of successes: 714/1000\n",
            "Average number of steps: 72.91736694677871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.3. Taxi-v3"
      ],
      "metadata": {
        "id": "oFKrACb4xKnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('Taxi-v3')\n",
        "\n",
        "start = time.time()\n",
        "optimal_v_values = value_iteration(env, max_iters=500, gamma=0.9)\n",
        "end = time.time()\n",
        "print(\"Runtime: \", end-start)\n",
        "\n",
        "optimal_policy = policy_extraction(env, optimal_v_values, gamma=0.9)\n",
        "winrate = play_multiple_times(env, optimal_policy, 1000)\n",
        "\n",
        "runtimes.append(end-start)\n",
        "winrates.append(winrate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiRg8rZ0IhBS",
        "outputId": "40a97852-8634-45cf-cbb1-5265343e90b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 116-th iteration.\n",
            "Runtime:  3.180743932723999\n",
            "Number of successes: 1000/1000\n",
            "Average number of steps: 13.096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runtime_data.append(runtimes)\n",
        "winrate_data.append(winrates)"
      ],
      "metadata": {
        "id": "ty_I5iFPMUow"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Policy Iteration"
      ],
      "metadata": {
        "id": "SvNq8V67ep2x"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcYV5xbSZAHe"
      },
      "source": [
        "def policy_iteration(env, max_iters, gamma=0.9):\n",
        "    # initialize\n",
        "    policy = np.zeros(env.observation_space.n, dtype=np.int)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        prev_policy = np.copy(policy)\n",
        "\n",
        "        # policy evaluation\n",
        "        v_values = policy_evaluation(env, policy, max_iters=max_iters, gamma=gamma)\n",
        "        \n",
        "        # policy improvement\n",
        "        policy = policy_extraction(env, v_values, gamma=gamma)\n",
        "\n",
        "        # check policy convergence\n",
        "        flag = True\n",
        "        for state in range(env.observation_space.n):\n",
        "            if prev_policy[state] != policy[state]:\n",
        "                flag = False\n",
        "                break\n",
        "        \n",
        "        if flag == True:\n",
        "            print(f'Converged at {i}-th iteration.')\n",
        "            break\n",
        "\n",
        "    return policy"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runtimes = []\n",
        "winrates = []"
      ],
      "metadata": {
        "id": "P6WBspOlMOMh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.1. FrozenLake-v1"
      ],
      "metadata": {
        "id": "VfufqsIrIk8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v1')\n",
        "\n",
        "start = time.time()\n",
        "optimal_policy = policy_iteration(env, max_iters=500, gamma=0.9)\n",
        "end = time.time()\n",
        "print(\"Runtime: \", end-start)\n",
        "\n",
        "winrate = play_multiple_times(env, optimal_policy, 1000)\n",
        "\n",
        "runtimes.append(end-start)\n",
        "winrates.append(winrate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "935fwzKLIpCo",
        "outputId": "3f30c2dd-0781-4557-803b-ded02e578603"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 5-th iteration.\n",
            "Runtime:  0.04864358901977539\n",
            "Number of successes: 716/1000\n",
            "Average number of steps: 37.54608938547486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.2. FrozenLake8x8-v1"
      ],
      "metadata": {
        "id": "pmKMA4OqIqmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake8x8-v1')\n",
        "\n",
        "start = time.time()\n",
        "optimal_policy = policy_iteration(env, max_iters=500, gamma=0.9)\n",
        "end = time.time()\n",
        "print(\"Runtime: \", end-start)\n",
        "\n",
        "winrate = play_multiple_times(env, optimal_policy, 1000)\n",
        "\n",
        "runtimes.append(end-start)\n",
        "winrates.append(winrate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKSCL9cbIuCp",
        "outputId": "055596aa-119d-4b38-90c0-5f6ba664336c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 9-th iteration.\n",
            "Runtime:  0.5882265567779541\n",
            "Number of successes: 733/1000\n",
            "Average number of steps: 70.02864938608458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.3. Taxi-v3"
      ],
      "metadata": {
        "id": "DKLf9EVfIuja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('Taxi-v3')\n",
        "\n",
        "start = time.time()\n",
        "optimal_policy = policy_iteration(env, max_iters=500, gamma=0.9)\n",
        "end = time.time()\n",
        "print(\"Runtime: \", end-start)\n",
        "\n",
        "winrate = play_multiple_times(env, optimal_policy, 1000)\n",
        "\n",
        "runtimes.append(end-start)\n",
        "winrates.append(winrate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb8AW7LbIyzi",
        "outputId": "15ccc62f-568a-417c-8c15-bbef2d9d824f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 16-th iteration.\n",
            "Runtime:  11.351135015487671\n",
            "Number of successes: 1000/1000\n",
            "Average number of steps: 13.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runtime_data.append(runtimes)\n",
        "winrate_data.append(winrates)"
      ],
      "metadata": {
        "id": "DUxcHNWSMcoZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Conclusion"
      ],
      "metadata": {
        "id": "ThrW-e9sMdYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runtime_df = pd.DataFrame(runtime_data, columns=['FrozenLake-v1', 'FrozenLake8x8-v1', 'taxi-v3'], \n",
        "                          index=['Value Iteration', 'Policy Iteration'])\n",
        "winrate_df = pd.DataFrame(winrate_data, columns=['FrozenLake-v1', 'FrozenLake8x8-v1', 'taxi-v3'], \n",
        "                          index=['Value Iteration', 'Policy Iteration'])\n",
        "runtime_df.columns = pd.MultiIndex.from_product([['RUNTIME'], runtime_df.columns.tolist()])\n",
        "winrate_df.columns = pd.MultiIndex.from_product([['WINRATE'], winrate_df.columns.tolist()])\n",
        "display.display(runtime_df)\n",
        "display.display(winrate_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "vSo1c7RCMib4",
        "outputId": "692f5898-ee26-4405-e6b2-a797b469935e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       RUNTIME                            \n",
              "                 FrozenLake-v1 FrozenLake8x8-v1    taxi-v3\n",
              "Value Iteration       0.047338         0.213910   3.180744\n",
              "Policy Iteration      0.048644         0.588227  11.351135"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e36ef01-e225-41de-bf9f-04d03820c7bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">RUNTIME</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>FrozenLake-v1</th>\n",
              "      <th>FrozenLake8x8-v1</th>\n",
              "      <th>taxi-v3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Value Iteration</th>\n",
              "      <td>0.047338</td>\n",
              "      <td>0.213910</td>\n",
              "      <td>3.180744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Policy Iteration</th>\n",
              "      <td>0.048644</td>\n",
              "      <td>0.588227</td>\n",
              "      <td>11.351135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e36ef01-e225-41de-bf9f-04d03820c7bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e36ef01-e225-41de-bf9f-04d03820c7bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e36ef01-e225-41de-bf9f-04d03820c7bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       WINRATE                         \n",
              "                 FrozenLake-v1 FrozenLake8x8-v1 taxi-v3\n",
              "Value Iteration          0.717            0.714     1.0\n",
              "Policy Iteration         0.716            0.733     1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd79f3a7-580e-4105-b8bf-5ab84663a1e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">WINRATE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>FrozenLake-v1</th>\n",
              "      <th>FrozenLake8x8-v1</th>\n",
              "      <th>taxi-v3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Value Iteration</th>\n",
              "      <td>0.717</td>\n",
              "      <td>0.714</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Policy Iteration</th>\n",
              "      <td>0.716</td>\n",
              "      <td>0.733</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd79f3a7-580e-4105-b8bf-5ab84663a1e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd79f3a7-580e-4105-b8bf-5ab84663a1e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd79f3a7-580e-4105-b8bf-5ab84663a1e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   Nhìn chung cả hai thuật toán đều đảm bảo hội tụ về một phương án tối ưu. \n",
        "#   Trong cả 3 games, Policy Iteration đều hội tụ về phương án tối ưu trong rất ít vòng lặp so với Value Iteration.\n",
        "#   Tuy nhiên thời gian tìm lời giải của Policy Iteration lâu hơn so với Value Iteration. Lý do \n",
        "#   là vì Policy Iteration tính quá nhiều lần v_value trong mỗi vòng lặp"
      ],
      "metadata": {
        "id": "HWoN6PU5OCSp"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}